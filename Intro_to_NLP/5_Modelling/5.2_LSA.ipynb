{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.2 LSA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from gensim import corpora\n",
    "from gensim.models import LsiModel\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"news_articles.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25626</td>\n",
       "      <td>One Weight-Loss Approach Fits All? No, Not Eve...</td>\n",
       "      <td>Dr. Frank Sacks, a professor of nutrition at H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19551</td>\n",
       "      <td>South Carolina Stuns Baylor to Reach the Round...</td>\n",
       "      <td>South Carolina’s win over   Duke was not only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25221</td>\n",
       "      <td>U.S. Presidential Race, Apple, Gene Wilder: Yo...</td>\n",
       "      <td>(Want to get this briefing by email? Here’s th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18026</td>\n",
       "      <td>His Predecessor Gone, Gambia’s New President F...</td>\n",
       "      <td>BANJUL, Gambia  —   A week after he was inaugu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21063</td>\n",
       "      <td>‘Harry Potter and the Cursed Child’ Goes From ...</td>\n",
       "      <td>The biggest book of the summer isn’t a blockbu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                              title  \\\n",
       "0  25626  One Weight-Loss Approach Fits All? No, Not Eve...   \n",
       "1  19551  South Carolina Stuns Baylor to Reach the Round...   \n",
       "2  25221  U.S. Presidential Race, Apple, Gene Wilder: Yo...   \n",
       "3  18026  His Predecessor Gone, Gambia’s New President F...   \n",
       "4  21063  ‘Harry Potter and the Cursed Child’ Goes From ...   \n",
       "\n",
       "                                             content  \n",
       "0  Dr. Frank Sacks, a professor of nutrition at H...  \n",
       "1  South Carolina’s win over   Duke was not only ...  \n",
       "2  (Want to get this briefing by email? Here’s th...  \n",
       "3  BANJUL, Gambia  —   A week after he was inaugu...  \n",
       "4  The biggest book of the summer isn’t a blockbu...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 3 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   id       100 non-null    int64 \n",
      " 1   title    100 non-null    object\n",
      " 2   content  100 non-null    object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 2.5+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sample = data.sample(20).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take just the content of the article, lowercase and remove punctuation\n",
    "articles = data_sample['content'].str.lower().apply(lambda x: re.sub(r\"([^\\w\\s])\", \"\", x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop word removal\n",
    "en_stopwords = stopwords.words('english')\n",
    "articles = articles.apply(lambda x: ' '.join([word for word in x.split() if word not in (en_stopwords)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize\n",
    "articles = articles.apply(lambda x: word_tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stemming (done for speed as we have a lot of text)\n",
    "ps = PorterStemmer()\n",
    "articles = articles.apply(lambda tokens: [ps.stem(token) for token in tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     [call, claus, sahar, kian, need, new, roommat,...\n",
       "1     [south, carolina, win, duke, surpris, fan, pos...\n",
       "2     [messeng, show, bushwick, brooklyn, sunday, la...\n",
       "3     [mogul, russel, simmon, team, univers, music, ...\n",
       "4     [presid, trump, ask, interview, saturday, resp...\n",
       "5     [complaint, gretchen, carlson, former, fox, ne...\n",
       "6     [lo, angel, shortli, drop, youngest, daughter,...\n",
       "7     [budapest, agn, galgoczi, 84, longer, make, to...\n",
       "8     [meet, donald, j, trump, nation, tech, elit, h...\n",
       "9     [beij, gener, war, resist, japanes, aggress, i...\n",
       "10    [storr, conn, one, year, ago, night, super, bo...\n",
       "11    [tuesday, presid, obama, pardon, commut, sente...\n",
       "12    [want, get, brief, email, here, good, even, he...\n",
       "13    [minneapoli, april, 21, news, spread, princ, f...\n",
       "14    [year, polit, convent, pull, amaz, feat, reboo...\n",
       "15    [new, york, citi, subway, train, jam, capac, p...\n",
       "16    [tesla, motor, maverick, maker, scrutini, fede...\n",
       "17    [republican, parti, trek, dark, took, fate, st...\n",
       "18    [dhaka, bangladesh, bangladesh, govern, move, ...\n",
       "19    [red, blue, optimist, fear, six, take, divid, ...\n",
       "Name: content, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'corpora' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# create dictionary of all words\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m dictionary \u001b[38;5;241m=\u001b[39m \u001b[43mcorpora\u001b[49m\u001b[38;5;241m.\u001b[39mDictionary(articles)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(dictionary)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'corpora' is not defined"
     ]
    }
   ],
   "source": [
    "# create dictionary of all words\n",
    "dictionary = corpora.Dictionary(articles)\n",
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dictionary' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# vecotize using bag of words into a document term matrix\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m doc_term \u001b[38;5;241m=\u001b[39m [\u001b[43mdictionary\u001b[49m\u001b[38;5;241m.\u001b[39mdoc2bow(text) \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m articles]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dictionary' is not defined"
     ]
    }
   ],
   "source": [
    "# vecotize using bag of words into a document term matrix\n",
    "doc_term = [dictionary.doc2bow(text) for text in articles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(doc_term)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# specify number of topics\n",
    "num_topics = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create LSA model\n",
    "lsamodel = LsiModel(doc_term, num_topics=num_topics, id2word = dictionary) \n",
    "print(lsamodel.print_topics(num_topics=num_topics, num_words=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine Number of Topics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate coherence scores to determine an optimum number of topics\n",
    "coherence_values = []\n",
    "model_list = []\n",
    "\n",
    "min_topics = 2\n",
    "max_topics = 11\n",
    "\n",
    "for num_topics_i in range(min_topics, max_topics+1):\n",
    "    model = LsiModel(doc_term, num_topics=num_topics_i, id2word = dictionary)\n",
    "    model_list.append(model)\n",
    "    coherence_model = CoherenceModel(model=model, texts=articles, dictionary=dictionary, coherence='c_v')\n",
    "    coherence_values.append(coherence_model.get_coherence())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(min_topics, max_topics+1), coherence_values)\n",
    "plt.xlabel(\"Number of Topics\")\n",
    "plt.ylabel(\"Coherence score\")\n",
    "plt.legend((\"coherence_values\"), loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_n_topics = 2\n",
    "lsamodel_f = LsiModel(doc_term, num_topics=final_n_topics, id2word = dictionary) \n",
    "print(lsamodel_f.print_topics(num_topics=final_n_topics, num_words=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
